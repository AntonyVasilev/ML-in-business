{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Russian Language Toxic Comments\n",
    "https://www.kaggle.com/blackmoon/russian-language-toxic-comments  \n",
    "Small dataset with labeled comments from 2ch.hk and pikabu.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./datasets/toxic_labeled.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.66514\n",
       "1.0    0.33486\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14412, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.0.1-cp38-cp38-win_amd64.whl (23.9 MB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\avasilev\\anaconda3\\lib\\site-packages (from gensim) (1.5.2)\n",
      "Requirement already satisfied: Cython==0.29.21 in c:\\users\\avasilev\\anaconda3\\lib\\site-packages (from gensim) (0.29.21)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-5.1.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\avasilev\\anaconda3\\lib\\site-packages (from gensim) (1.19.2)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.0.1 smart-open-5.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\AVasilev\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "import pymorphy2\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_ru = stopwords.words('russian')\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('stopwords.txt') as f:\n",
    "    additional_stopwords = [w.strip() for w in f.readlines() if w]\n",
    "stopword_ru += additional_stopwords\n",
    "len(stopword_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    '''\n",
    "    очистка текста\n",
    "    \n",
    "    на выходе очищеный текст\n",
    "    \n",
    "    '''\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = text.strip('\\n').strip('\\r').strip('\\t')\n",
    "    text = re.sub(\"-\\s\\r\\n\\|-\\s\\r\\n|\\r\\n\", '', str(text))\n",
    "\n",
    "    text = re.sub(\"[0-9]|[-—.,:;_%©«»?*!@#№$^•·&()]|[+=]|[[]|[]]|[/]|\", '', text)\n",
    "    text = re.sub(r\"\\r\\n\\t|\\n|\\\\s|\\r\\t|\\\\n\", ' ', text)\n",
    "    text = re.sub(r'[\\xad]|[\\s+]', ' ', text.strip())\n",
    "    text = re.sub(\"n\", ' ', text)\n",
    "\n",
    "    \n",
    "    #tokens = list(tokenize(text))\n",
    "    #words = [_.text for _ in tokens]\n",
    "    #words = [w for w in words if w not in stopword_ru]\n",
    "    \n",
    "    #return \" \".join(words)\n",
    "    return text\n",
    "\n",
    "cache = {}\n",
    "\n",
    "def lemmatization(text):\n",
    "    '''\n",
    "    лемматизация\n",
    "        [0] если зашел тип не `str` делаем его `str`\n",
    "        [1] токенизация предложения через razdel\n",
    "        [2] проверка есть ли в начале слова '-'\n",
    "        [3] проверка токена с одного символа\n",
    "        [4] проверка есть ли данное слово в кэше\n",
    "        [5] лемматизация слова\n",
    "        [6] проверка на стоп-слова\n",
    "\n",
    "    на выходе лист отлемматизированых токенов\n",
    "    '''\n",
    "\n",
    "    # [0]\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    \n",
    "    # [1]\n",
    "    tokens = list(tokenize(text))\n",
    "    #print(tokens)\n",
    "    words = [_.text for _ in tokens]\n",
    "\n",
    "    words_lem = []\n",
    "    for w in words:\n",
    "        if w[0] == '-': # [2]\n",
    "            w = w[1:]\n",
    "        if len(w)>1: # [3]\n",
    "            if w in cache: # [4]\n",
    "                words_lem.append(cache[w])\n",
    "                #print(temp_cach)\n",
    "            else: # [5]\n",
    "                temp_cach = cache[w] = morph.parse(w)[0].normal_form\n",
    "                words_lem.append(temp_cach)\n",
    "                #print(w,' : ',temp_cach)\n",
    "    \n",
    "    words_lem_without_stopwords=[i for i in words_lem if not i in stopword_ru] # [6]\n",
    "    #print(words_lem_without_stopwords)\n",
    "    return words_lem_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 817 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['comment'] = df['comment'].apply(lambda x: clean_text(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['comment'] = df['comment'].apply(lambda x: lemmatization(x), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[верблюдовто, дебил, бл]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[хохол, это, отдушина, затюканый, россиянин, м...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[собака, собачий, смерть]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[страница, обновить, дебил, это, оскорбление, ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[убедить, страничный, пдф, скрипаль, отравить,...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0                           [верблюдовто, дебил, бл]    1.0\n",
       "1  [хохол, это, отдушина, затюканый, россиянин, м...    1.0\n",
       "2                          [собака, собачий, смерть]    1.0\n",
       "3  [страница, обновить, дебил, это, оскорбление, ...    1.0\n",
       "4  [убедить, страничный, пдф, скрипаль, отравить,...    1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>[вонючий, совковый, скот, прибежать, ныть, сто...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14408</th>\n",
       "      <td>[любить, гоблин, тупорылый, чтоль, какуюнибудь...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14409</th>\n",
       "      <td>[посмотреть, утомлённый, солнце, оказаться, эт...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14410</th>\n",
       "      <td>[крымотред, нарушать, правило, раздел, тк, нем...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14411</th>\n",
       "      <td>[сей, пора, пересматривать, видео, орамбо, кст...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  toxic\n",
       "14407  [вонючий, совковый, скот, прибежать, ныть, сто...    1.0\n",
       "14408  [любить, гоблин, тупорылый, чтоль, какуюнибудь...    1.0\n",
       "14409  [посмотреть, утомлённый, солнце, оказаться, эт...    0.0\n",
       "14410  [крымотред, нарушать, правило, раздел, тк, нем...    1.0\n",
       "14411  [сей, пора, пересматривать, видео, орамбо, кст...    0.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сформируем список наших текстов, разбив еще и на пробелы\n",
    "comments = [t for t in df['comment'].values]\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(comments)\n",
    "common_corpus = [common_dictionary.doc2bow(comment) for comment in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35543"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(common_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'бл',\n",
       " 1: 'верблюдовто',\n",
       " 2: 'дебил',\n",
       " 3: 'вон',\n",
       " 4: 'ещё',\n",
       " 5: 'затюканый',\n",
       " 6: 'кисель',\n",
       " 7: 'мол',\n",
       " 8: 'отдушина',\n",
       " 9: 'плохой',\n",
       " 10: 'придумать',\n",
       " 11: 'россиянин',\n",
       " 12: 'хохлов',\n",
       " 13: 'хохол',\n",
       " 14: 'это',\n",
       " 15: 'смерть',\n",
       " 16: 'собака',\n",
       " 17: 'собачий',\n",
       " 18: 'верить',\n",
       " 19: 'воображать',\n",
       " 20: 'доказать',\n",
       " 21: 'друг',\n",
       " 22: 'множественный',\n",
       " 23: 'недебил',\n",
       " 24: 'обновить',\n",
       " 25: 'оскорбление',\n",
       " 26: 'писать',\n",
       " 27: 'страница',\n",
       " 28: 'твой',\n",
       " 29: 'факт',\n",
       " 30: 'число',\n",
       " 31: 'анализировать',\n",
       " 32: 'ватник',\n",
       " 33: 'думать',\n",
       " 34: 'отравить',\n",
       " 35: 'пдф',\n",
       " 36: 'пытаться',\n",
       " 37: 'россия',\n",
       " 38: 'скрипаль',\n",
       " 39: 'страничный',\n",
       " 40: 'убедить',\n",
       " 41: 'здравоохранение',\n",
       " 42: 'зимбабве',\n",
       " 43: 'рф',\n",
       " 44: 'система',\n",
       " 45: 'современный',\n",
       " 46: 'стан',\n",
       " 47: 'тупой',\n",
       " 48: 'эталон',\n",
       " 49: 'являться',\n",
       " 50: 'абсолютный',\n",
       " 51: 'борд',\n",
       " 52: 'брипидор',\n",
       " 53: 'дно',\n",
       " 54: 'заменить',\n",
       " 55: 'игнорировать',\n",
       " 56: 'инф',\n",
       " 57: 'лишить',\n",
       " 58: 'марвести',\n",
       " 59: 'модератор',\n",
       " 60: 'неадекват',\n",
       " 61: 'неадекватность',\n",
       " 62: 'недостаточно',\n",
       " 63: 'нужно',\n",
       " 64: 'полномочие',\n",
       " 65: 'понять',\n",
       " 66: 'пост',\n",
       " 67: 'пробивать',\n",
       " 68: 'репортить',\n",
       " 69: 'ссылка',\n",
       " 70: 'текущий',\n",
       " 71: 'фильм',\n",
       " 72: 'фраза',\n",
       " 73: 'шапка',\n",
       " 74: 'китаз',\n",
       " 75: 'мочь',\n",
       " 76: 'нормально',\n",
       " 77: 'пош',\n",
       " 78: 'разворовать',\n",
       " 79: 'сделать',\n",
       " 80: 'строить',\n",
       " 81: 'технология',\n",
       " 82: 'трещина',\n",
       " 83: 'упад',\n",
       " 84: 'ебать',\n",
       " 85: 'разносить',\n",
       " 86: 'шизик',\n",
       " 87: 'обосраться',\n",
       " 88: 'обтекать',\n",
       " 89: 'сидеть',\n",
       " 90: 'губа',\n",
       " 91: 'дегенерат',\n",
       " 92: 'засос',\n",
       " 93: 'поцелуй',\n",
       " 94: 'хуйня',\n",
       " 95: 'etaru',\n",
       " 96: 'pla',\n",
       " 97: 'ан',\n",
       " 98: 'бактерия',\n",
       " 99: 'бред',\n",
       " 100: 'вещать',\n",
       " 101: 'война',\n",
       " 102: 'всё',\n",
       " 103: 'второй',\n",
       " 104: 'действительно',\n",
       " 105: 'заказать',\n",
       " 106: 'извинить',\n",
       " 107: 'изъясняться',\n",
       " 108: 'истый',\n",
       " 109: 'какойтый',\n",
       " 110: 'книга',\n",
       " 111: 'логично',\n",
       " 112: 'маняграфия',\n",
       " 113: 'мировой',\n",
       " 114: 'написать',\n",
       " 115: 'обратить',\n",
       " 116: 'ой',\n",
       " 117: 'определённый',\n",
       " 118: 'подробный',\n",
       " 119: 'проблема',\n",
       " 120: 'просто',\n",
       " 121: 'рик',\n",
       " 122: 'сахаров',\n",
       " 123: 'условие',\n",
       " 124: 'учиться',\n",
       " 125: 'чернь',\n",
       " 126: 'шваль',\n",
       " 127: 'bud',\n",
       " 128: 'dezsluzhbyi',\n",
       " 129: 'https',\n",
       " 130: 'obyich',\n",
       " 131: 'pikaburu',\n",
       " 132: 'story',\n",
       " 133: 'yie',\n",
       " 134: 'авторамочь',\n",
       " 135: 'надеяться',\n",
       " 136: 'найти',\n",
       " 137: 'нибыть',\n",
       " 138: 'полезный',\n",
       " 139: 'помочь',\n",
       " 140: 'почитать',\n",
       " 141: 'поколение',\n",
       " 142: 'родиться',\n",
       " 143: 'семья',\n",
       " 144: 'урод',\n",
       " 145: 'безмозглый',\n",
       " 146: 'модер',\n",
       " 147: 'позвать',\n",
       " 148: 'врать',\n",
       " 149: 'костюм',\n",
       " 150: 'миллиардер',\n",
       " 151: 'пруф',\n",
       " 152: 'террористторчёкшизофреник',\n",
       " 153: 'учёный',\n",
       " 154: 'филантроп',\n",
       " 155: 'хороший',\n",
       " 156: 'чуткий',\n",
       " 157: 'вдвойне',\n",
       " 158: 'весь',\n",
       " 159: 'главное',\n",
       " 160: 'жизнь',\n",
       " 161: 'кстати',\n",
       " 162: 'кукареканье',\n",
       " 163: 'наплевать',\n",
       " 164: 'тупорылый',\n",
       " 165: 'уровень',\n",
       " 166: 'форумапомойка',\n",
       " 167: 'fs',\n",
       " 168: 'mw',\n",
       " 169: 'riva',\n",
       " 170: 'ti',\n",
       " 171: 'type',\n",
       " 172: 'ведьмак',\n",
       " 173: 'видеокарта',\n",
       " 174: 'гб',\n",
       " 175: 'глаз',\n",
       " 176: 'год',\n",
       " 177: 'график',\n",
       " 178: 'графика',\n",
       " 179: 'гта',\n",
       " 180: 'джойстик',\n",
       " 181: 'достаточно',\n",
       " 182: 'дрочева',\n",
       " 183: 'забиваться',\n",
       " 184: 'забить',\n",
       " 185: 'заканчивать',\n",
       " 186: 'игра',\n",
       " 187: 'играть',\n",
       " 188: 'иксбокс',\n",
       " 189: 'кнопка',\n",
       " 190: 'комп',\n",
       " 191: 'который',\n",
       " 192: 'кроме',\n",
       " 193: 'купить',\n",
       " 194: 'куча',\n",
       " 195: 'мб',\n",
       " 196: 'мешать',\n",
       " 197: 'минимум',\n",
       " 198: 'мобильный',\n",
       " 199: 'начать',\n",
       " 200: 'начинать',\n",
       " 201: 'обидно',\n",
       " 202: 'переходник',\n",
       " 203: 'плойка',\n",
       " 204: 'повод',\n",
       " 205: 'понизить',\n",
       " 206: 'понимать',\n",
       " 207: 'потенциал',\n",
       " 208: 'проходить',\n",
       " 209: 'пятый',\n",
       " 210: 'распродажа',\n",
       " 211: 'резать',\n",
       " 212: 'самый',\n",
       " 213: 'серия',\n",
       " 214: 'спокойно',\n",
       " 215: 'танк',\n",
       " 216: 'текстура',\n",
       " 217: 'требовать',\n",
       " 218: 'ультр',\n",
       " 219: 'управление',\n",
       " 220: 'хватать',\n",
       " 221: 'часть',\n",
       " 222: 'бедный',\n",
       " 223: 'будущее',\n",
       " 224: 'ванька',\n",
       " 225: 'воевак',\n",
       " 226: 'вообще',\n",
       " 227: 'гейгорка',\n",
       " 228: 'глупый',\n",
       " 229: 'гоблач',\n",
       " 230: 'головушка',\n",
       " 231: 'далёкий',\n",
       " 232: 'жаль',\n",
       " 233: 'жирный',\n",
       " 234: 'идти',\n",
       " 235: 'истеричка',\n",
       " 236: 'личный',\n",
       " 237: 'мимо',\n",
       " 238: 'наебали',\n",
       " 239: 'невоспитанный',\n",
       " 240: 'обмануть',\n",
       " 241: 'ответственность',\n",
       " 242: 'отгрызть',\n",
       " 243: 'очень',\n",
       " 244: 'подать',\n",
       " 245: 'подзалупный',\n",
       " 246: 'пойти',\n",
       " 247: 'поплакать',\n",
       " 248: 'поступок',\n",
       " 249: 'приживал',\n",
       " 250: 'прошлое',\n",
       " 251: 'ресентимент',\n",
       " 252: 'рука',\n",
       " 253: 'свой',\n",
       " 254: 'снимать',\n",
       " 255: 'ушлый',\n",
       " 256: 'чекист',\n",
       " 257: 'детство',\n",
       " 258: 'мать',\n",
       " 259: 'мэдисон',\n",
       " 260: 'нравиться',\n",
       " 261: 'прикидываться',\n",
       " 262: 'ронять',\n",
       " 263: 'стример',\n",
       " 264: 'троллинг',\n",
       " 265: 'говнокоммент',\n",
       " 266: 'комментарий',\n",
       " 267: 'ниже',\n",
       " 268: 'отметка',\n",
       " 269: 'посмотреть',\n",
       " 270: 'процент',\n",
       " 271: 'средний',\n",
       " 272: 'спалиться',\n",
       " 273: 'утверждать',\n",
       " 274: 'чмоха',\n",
       " 275: 'бандит',\n",
       " 276: 'град',\n",
       " 277: 'ести',\n",
       " 278: 'засылать',\n",
       " 279: 'ихтамнет',\n",
       " 280: 'маня',\n",
       " 281: 'оба',\n",
       " 282: 'отношение',\n",
       " 283: 'парень',\n",
       " 284: 'партия',\n",
       " 285: 'пидаран',\n",
       " 286: 'пиздежа',\n",
       " 287: 'поддерживаться',\n",
       " 288: 'разжигаться',\n",
       " 289: 'роиса',\n",
       " 290: 'роися',\n",
       " 291: 'руснявый',\n",
       " 292: 'смотреть',\n",
       " 293: 'спидознать',\n",
       " 294: 'страна',\n",
       " 295: 'тварь',\n",
       " 296: 'террорист',\n",
       " 297: 'украина',\n",
       " 298: 'харк',\n",
       " 299: 'хуярить',\n",
       " 300: 'весёлый',\n",
       " 301: 'нация',\n",
       " 302: 'опровергнуть',\n",
       " 303: 'причём',\n",
       " 304: 'считать',\n",
       " 305: 'чувство',\n",
       " 306: 'юмор',\n",
       " 307: 'агрессия',\n",
       " 308: 'дерьмо',\n",
       " 309: 'отрицательный',\n",
       " 310: 'ткнуть',\n",
       " 311: 'эмоция',\n",
       " 312: 'барин',\n",
       " 313: 'заморский',\n",
       " 314: 'иметь',\n",
       " 315: 'кремль',\n",
       " 316: 'против',\n",
       " 317: 'холоп',\n",
       " 318: 'вау',\n",
       " 319: 'гуглита',\n",
       " 320: 'еблом',\n",
       " 321: 'незнакомый',\n",
       " 322: 'никто',\n",
       " 323: 'нож',\n",
       " 324: 'нужный',\n",
       " 325: 'ох',\n",
       " 326: 'подсказать',\n",
       " 327: 'рязанский',\n",
       " 328: 'селюк',\n",
       " 329: 'словечко',\n",
       " 330: 'сторона',\n",
       " 331: 'тред',\n",
       " 332: 'хвастаться',\n",
       " 333: 'ваш',\n",
       " 334: 'верно',\n",
       " 335: 'ебануть',\n",
       " 336: 'жить',\n",
       " 337: 'мир',\n",
       " 338: 'объяснить',\n",
       " 339: 'пока',\n",
       " 340: 'поржать',\n",
       " 341: 'потреблять',\n",
       " 342: 'приспособиться',\n",
       " 343: 'продавать',\n",
       " 344: 'скорее',\n",
       " 345: 'смешно',\n",
       " 346: 'удобный',\n",
       " 347: 'узко',\n",
       " 348: 'утверждение',\n",
       " 349: 'хавка',\n",
       " 350: 'цацка',\n",
       " 351: 'cohwqfbgjwejpg',\n",
       " 352: 'ppuserapicom',\n",
       " 353: 'беларусь',\n",
       " 354: 'белоррусский',\n",
       " 355: 'ввести',\n",
       " 356: 'вводить',\n",
       " 357: 'вещь',\n",
       " 358: 'давно',\n",
       " 359: 'допустить',\n",
       " 360: 'ездить',\n",
       " 361: 'инфожд',\n",
       " 362: 'искать',\n",
       " 363: 'либерал',\n",
       " 364: 'логачевболашенко',\n",
       " 365: 'независимый',\n",
       " 366: 'новороссия',\n",
       " 367: 'новохуесоссия',\n",
       " 368: 'новшевство',\n",
       " 369: 'определение',\n",
       " 370: 'отлично',\n",
       " 371: 'поезд',\n",
       " 372: 'поехать',\n",
       " 373: 'позволять',\n",
       " 374: 'полигон',\n",
       " 375: 'польский',\n",
       " 376: 'прекрасно',\n",
       " 377: 'пригородный',\n",
       " 378: 'проводить',\n",
       " 379: 'пруфа',\n",
       " 380: 'пынь',\n",
       " 381: 'русский',\n",
       " 382: 'сначала',\n",
       " 383: 'специально',\n",
       " 384: 'справка',\n",
       " 385: 'терпеть',\n",
       " 386: 'терпильность',\n",
       " 387: 'украинский',\n",
       " 388: 'учить',\n",
       " 389: 'читать',\n",
       " 390: 'читаться',\n",
       " 391: 'эксперемент',\n",
       " 392: 'эксперементальный',\n",
       " 393: 'якобы',\n",
       " 394: 'ясно',\n",
       " 395: 'пиздец',\n",
       " 396: 'руснить',\n",
       " 397: 'большой',\n",
       " 398: 'вопрос',\n",
       " 399: 'высера',\n",
       " 400: 'животное',\n",
       " 401: 'нету',\n",
       " 402: 'нечего',\n",
       " 403: 'отвечать',\n",
       " 404: 'понимание',\n",
       " 405: 'представитель',\n",
       " 406: 'сказать',\n",
       " 407: 'типичный',\n",
       " 408: 'травля',\n",
       " 409: 'диванный',\n",
       " 410: 'обычно',\n",
       " 411: 'политолог',\n",
       " 412: 'слиться',\n",
       " 413: 'вплоть',\n",
       " 414: 'долбоести',\n",
       " 415: 'дурак',\n",
       " 416: 'называть',\n",
       " 417: 'пикаба',\n",
       " 418: 'пора',\n",
       " 419: 'правило',\n",
       " 420: 'призвать',\n",
       " 421: 'работать',\n",
       " 422: 'случай',\n",
       " 423: 'считаться',\n",
       " 424: 'тысяча',\n",
       " 425: 'угодный',\n",
       " 426: 'удалять',\n",
       " 427: 'удаляться',\n",
       " 428: 'glassdoor',\n",
       " 429: 'американец',\n",
       " 430: 'бодить',\n",
       " 431: 'бодишоп',\n",
       " 432: 'видеть',\n",
       " 433: 'виза',\n",
       " 434: 'выдумать',\n",
       " 435: 'деться',\n",
       " 436: 'завидовать',\n",
       " 437: 'зайти',\n",
       " 438: 'запрещать',\n",
       " 439: 'зарплата',\n",
       " 440: 'знакомый',\n",
       " 441: 'знать',\n",
       " 442: 'какомтый',\n",
       " 443: 'короче',\n",
       " 444: 'либо',\n",
       " 445: 'лох',\n",
       " 446: 'медианный',\n",
       " 447: 'методичка',\n",
       " 448: 'наш',\n",
       " 449: 'никуда',\n",
       " 450: 'перевозить',\n",
       " 451: 'пиздабол',\n",
       " 452: 'позориться',\n",
       " 453: 'прочитать',\n",
       " 454: 'работодатель',\n",
       " 455: 'рабство',\n",
       " 456: 'равно',\n",
       " 457: 'смена',\n",
       " 458: 'смочь',\n",
       " 459: 'сразу',\n",
       " 460: 'ссать',\n",
       " 461: 'страховка',\n",
       " 462: 'тема',\n",
       " 463: 'туда',\n",
       " 464: 'ухо',\n",
       " 465: 'учёт',\n",
       " 466: 'цифра',\n",
       " 467: 'человек',\n",
       " 468: 'шоп',\n",
       " 469: 'etc',\n",
       " 470: 'sjw',\n",
       " 471: 'азия',\n",
       " 472: 'араб',\n",
       " 473: 'африка',\n",
       " 474: 'африканец',\n",
       " 475: 'беженец',\n",
       " 476: 'белые',\n",
       " 477: 'белый',\n",
       " 478: 'биг',\n",
       " 479: 'ближний',\n",
       " 480: 'болгария',\n",
       " 481: 'большинство',\n",
       " 482: 'брак',\n",
       " 483: 'бутылка',\n",
       " 484: 'бывший',\n",
       " 485: 'великобритания',\n",
       " 486: 'венгрия',\n",
       " 487: 'вестись',\n",
       " 488: 'взять',\n",
       " 489: 'власть',\n",
       " 490: 'восток',\n",
       " 491: 'вроде',\n",
       " 492: 'вымереть',\n",
       " 493: 'вымирание',\n",
       " 494: 'вымирать',\n",
       " 495: 'вырождаться',\n",
       " 496: 'выходец',\n",
       " 497: 'вышеперечисленный',\n",
       " 498: 'германия',\n",
       " 499: 'гетто',\n",
       " 500: 'говорить',\n",
       " 501: 'гораздо',\n",
       " 502: 'город',\n",
       " 503: 'господствующий',\n",
       " 504: 'греция',\n",
       " 505: 'грозить',\n",
       " 506: 'деградировать',\n",
       " 507: 'делаться',\n",
       " 508: 'демонизация',\n",
       " 509: 'детейметис',\n",
       " 510: 'должный',\n",
       " 511: 'доминировать',\n",
       " 512: 'ебеня',\n",
       " 513: 'европа',\n",
       " 514: 'ждать',\n",
       " 515: 'женщина',\n",
       " 516: 'завоз',\n",
       " 517: 'закон',\n",
       " 518: 'замещение',\n",
       " 519: 'занимать',\n",
       " 520: 'западноевропейский',\n",
       " 521: 'западный',\n",
       " 522: 'затрагивать',\n",
       " 523: 'империя',\n",
       " 524: 'иначе',\n",
       " 525: 'индиец',\n",
       " 526: 'исламизация',\n",
       " 527: 'кавказ',\n",
       " 528: 'кавказец',\n",
       " 529: 'каждый',\n",
       " 530: 'качество',\n",
       " 531: 'когдато',\n",
       " 532: 'колонизировать',\n",
       " 533: 'контактировать',\n",
       " 534: 'коренной',\n",
       " 535: 'космополитизм',\n",
       " 536: 'крупный',\n",
       " 537: 'культура',\n",
       " 538: 'латвия',\n",
       " 539: 'лгбт',\n",
       " 540: 'леволиберальный',\n",
       " 541: 'литва',\n",
       " 542: 'лишиться',\n",
       " 543: 'лёгкий',\n",
       " 544: 'македония',\n",
       " 545: 'маленький',\n",
       " 546: 'масштаб',\n",
       " 547: 'межрасовый',\n",
       " 548: 'мексика',\n",
       " 549: 'место',\n",
       " 550: 'метис',\n",
       " 551: 'метисация',\n",
       " 552: 'миграция',\n",
       " 553: 'молдова',\n",
       " 554: 'молодой',\n",
       " 555: 'мужчина',\n",
       " 556: 'мужчинамигрант',\n",
       " 557: 'мультикультурализм',\n",
       " 558: 'набирать',\n",
       " 559: 'нагибать',\n",
       " 560: 'наделять',\n",
       " 561: 'наоборот',\n",
       " 562: 'направить',\n",
       " 563: 'например',\n",
       " 564: 'народ',\n",
       " 565: 'насаждение',\n",
       " 566: 'население',\n",
       " 567: 'небелый',\n",
       " 568: 'негр',\n",
       " 569: 'нейтральный',\n",
       " 570: 'ниггероарабский',\n",
       " 571: 'новый',\n",
       " 572: 'обожествлять',\n",
       " 573: 'обсуждение',\n",
       " 574: 'оставаться',\n",
       " 575: 'остаться',\n",
       " 576: 'отдельный',\n",
       " 577: 'относиться',\n",
       " 578: 'официально',\n",
       " 579: 'пакистанец',\n",
       " 580: 'переехать',\n",
       " 581: 'победить',\n",
       " 582: 'политика',\n",
       " 583: 'политкорректность',\n",
       " 584: 'половина',\n",
       " 585: 'польша',\n",
       " 586: 'популярность',\n",
       " 587: 'почернение',\n",
       " 588: 'превосходство',\n",
       " 589: 'преступность',\n",
       " 590: 'пример',\n",
       " 591: 'пришлый',\n",
       " 592: 'проводиться',\n",
       " 593: 'происходить',\n",
       " 594: 'пропаганда',\n",
       " 595: 'пропагандироваться',\n",
       " 596: 'противоположный',\n",
       " 597: 'прямой',\n",
       " 598: 'пучок',\n",
       " 599: 'раса',\n",
       " 600: 'результат',\n",
       " 601: 'рождаемость',\n",
       " 602: 'румыния',\n",
       " 603: 'свобода',\n",
       " 604: 'сегодня',\n",
       " 605: 'сербия',\n",
       " 606: 'сильный',\n",
       " 607: 'ситуация',\n",
       " 608: 'скандинавия',\n",
       " 609: 'слабый',\n",
       " 610: 'словакия',\n",
       " 611: 'словения',\n",
       " 612: 'слово',\n",
       " 613: 'смешанный',\n",
       " 614: 'смуглый',\n",
       " 615: 'смысл',\n",
       " 616: 'снижение',\n",
       " 617: 'создание',\n",
       " 618: 'сознательный',\n",
       " 619: 'сохранение',\n",
       " 620: 'страшно',\n",
       " 621: 'сша',\n",
       " 622: 'также',\n",
       " 623: 'толерантность',\n",
       " 624: 'толерантный',\n",
       " 625: 'традиционный',\n",
       " 626: 'украинец',\n",
       " 627: 'феминизм',\n",
       " 628: 'феминистка',\n",
       " 629: 'форс',\n",
       " 630: 'франция',\n",
       " 631: 'хорватия',\n",
       " 632: 'хотеть',\n",
       " 633: 'хуй',\n",
       " 634: 'ценность',\n",
       " 635: 'чайлдфри',\n",
       " 636: 'чемтый',\n",
       " 637: 'чернильница',\n",
       " 638: 'черногория',\n",
       " 639: 'чернокоричневый',\n",
       " 640: 'чехия',\n",
       " 641: 'чудовищный',\n",
       " 642: 'чурка',\n",
       " 643: 'чёрный',\n",
       " 644: 'швеция',\n",
       " 645: 'эстония',\n",
       " 646: 'этнический',\n",
       " 647: 'южный',\n",
       " 648: 'видно',\n",
       " 649: 'видный',\n",
       " 650: 'внезапно',\n",
       " 651: 'задвигать',\n",
       " 652: 'закавказье',\n",
       " 653: 'казахский',\n",
       " 654: 'кириллица',\n",
       " 655: 'латинница',\n",
       " 656: 'маразматик',\n",
       " 657: 'оказаться',\n",
       " 658: 'ошибаться',\n",
       " 659: 'пол',\n",
       " 660: 'прибалтика',\n",
       " 661: 'слон',\n",
       " 662: 'сорт',\n",
       " 663: 'спороть',\n",
       " 664: 'старый',\n",
       " 665: 'язык',\n",
       " 666: 'автор',\n",
       " 667: 'активность',\n",
       " 668: 'аффективный',\n",
       " 669: 'бессвязность',\n",
       " 670: 'больной',\n",
       " 671: 'внешний',\n",
       " 672: 'возникать',\n",
       " 673: 'время',\n",
       " 674: 'выделять',\n",
       " 675: 'выражаться',\n",
       " 676: 'высказывание',\n",
       " 677: 'глоссоманиакальный',\n",
       " 678: 'доступность',\n",
       " 679: 'интеллектуальный',\n",
       " 680: 'крепелин',\n",
       " 681: 'монолог',\n",
       " 682: 'морфемный',\n",
       " 683: 'мышление',\n",
       " 684: 'нагрузка',\n",
       " 685: 'название',\n",
       " 686: 'напор',\n",
       " 687: 'нарушение',\n",
       " 688: 'неистощимость',\n",
       " 689: 'некоторый',\n",
       " 690: 'несвязанный',\n",
       " 691: 'нести',\n",
       " 692: 'никакой',\n",
       " 693: 'общение',\n",
       " 694: 'однако',\n",
       " 695: 'особый',\n",
       " 696: 'отличие',\n",
       " 697: 'отличительный',\n",
       " 698: 'относительный',\n",
       " 699: 'отражать',\n",
       " 700: 'отсутствие',\n",
       " 701: 'параноидный',\n",
       " 702: 'пациент',\n",
       " 703: 'повышенный',\n",
       " 704: 'помимо',\n",
       " 705: 'понятие',\n",
       " 706: 'поток',\n",
       " 707: 'потребность',\n",
       " 708: 'правильно',\n",
       " 709: 'прежде',\n",
       " 710: 'преимущественный',\n",
       " 711: 'продукция',\n",
       " 712: 'психический',\n",
       " 713: 'разорванность',\n",
       " 714: 'расстройство',\n",
       " 715: 'речевой',\n",
       " 716: 'речь',\n",
       " 717: 'симптом',\n",
       " 718: 'слабоумие',\n",
       " 719: 'словообразование',\n",
       " 720: 'смысловой',\n",
       " 721: 'собеседник',\n",
       " 722: 'содержание',\n",
       " 723: 'соответствовать',\n",
       " 724: 'сохранность',\n",
       " 725: 'сочетаться',\n",
       " 726: 'строиться',\n",
       " 727: 'структура',\n",
       " 728: 'тяжёлый',\n",
       " 729: 'упорядоченность',\n",
       " 730: 'форма',\n",
       " 731: 'характеризоваться',\n",
       " 732: 'характерный',\n",
       " 733: 'черта',\n",
       " 734: 'шизофазия',\n",
       " 735: 'шизофрения',\n",
       " 736: 'абортировать',\n",
       " 737: 'бумага',\n",
       " 738: 'вода',\n",
       " 739: 'высокий',\n",
       " 740: 'газета',\n",
       " 741: 'девушка',\n",
       " 742: 'дефицит',\n",
       " 743: 'жопа',\n",
       " 744: 'заряжать',\n",
       " 745: 'красивый',\n",
       " 746: 'любитель',\n",
       " 747: 'медецин',\n",
       " 748: 'мнение',\n",
       " 749: 'новиоп',\n",
       " 750: 'образование',\n",
       " 751: 'плагиат',\n",
       " 752: 'подтирать',\n",
       " 753: 'совка',\n",
       " 754: 'телевизор',\n",
       " 755: 'техника',\n",
       " 756: 'товар',\n",
       " 757: 'туалетный',\n",
       " 758: 'аллах',\n",
       " 759: 'житель',\n",
       " 760: 'какл',\n",
       " 761: 'манямирок',\n",
       " 762: 'нищий',\n",
       " 763: 'окраина',\n",
       " 764: 'папуасий',\n",
       " 765: 'полубандитский',\n",
       " 766: 'самоподдуть',\n",
       " 767: 'acca',\n",
       " 768: 'ap',\n",
       " 769: 'apc',\n",
       " 770: 'co',\n",
       " 771: 'oc',\n",
       " 772: 'op',\n",
       " 773: 'opo',\n",
       " 774: 'pa',\n",
       " 775: 'pac',\n",
       " 776: 'pacc',\n",
       " 777: 'po',\n",
       " 778: 'poc',\n",
       " 779: 'бу',\n",
       " 780: 'везти',\n",
       " 781: 'ви',\n",
       " 782: 'вии',\n",
       " 783: 'вит',\n",
       " 784: 'влен',\n",
       " 785: 'влять',\n",
       " 786: 'вт',\n",
       " 787: 'выд',\n",
       " 788: 'гих',\n",
       " 789: 'гута',\n",
       " 790: 'дде',\n",
       " 791: 'депуты',\n",
       " 792: 'дин',\n",
       " 793: 'дит',\n",
       " 794: 'дитель',\n",
       " 795: 'дить',\n",
       " 796: 'ды',\n",
       " 797: 'дят',\n",
       " 798: 'ед',\n",
       " 799: 'ект',\n",
       " 800: 'ель',\n",
       " 801: 'ен',\n",
       " 802: 'ение',\n",
       " 803: 'есить',\n",
       " 804: 'ет',\n",
       " 805: 'еш',\n",
       " 806: 'ешение',\n",
       " 807: 'ждения',\n",
       " 808: 'жи',\n",
       " 809: 'зв',\n",
       " 810: 'зн',\n",
       " 811: 'ивилегия',\n",
       " 812: 'ким',\n",
       " 813: 'ких',\n",
       " 814: 'кл',\n",
       " 815: 'кт',\n",
       " 816: 'лек',\n",
       " 817: 'летний',\n",
       " 818: 'лита',\n",
       " 819: 'лнил',\n",
       " 820: 'лу',\n",
       " 821: 'луч',\n",
       " 822: 'лучить',\n",
       " 823: 'лы',\n",
       " 824: 'льный',\n",
       " 825: 'льший',\n",
       " 826: 'льшина',\n",
       " 827: 'мблей',\n",
       " 828: 'ме',\n",
       " 829: 'менее',\n",
       " 830: 'му',\n",
       " 831: 'нев',\n",
       " 832: 'нега',\n",
       " 833: 'нез',\n",
       " 834: 'немна',\n",
       " 835: 'ниченный',\n",
       " 836: 'нн',\n",
       " 837: 'нёбо',\n",
       " 838: 'пыт',\n",
       " 839: 'ребёнок',\n",
       " 840: 'твенна',\n",
       " 841: 'тву',\n",
       " 842: 'твующег',\n",
       " 843: 'тельна',\n",
       " 844: 'тк',\n",
       " 845: 'ть',\n",
       " 846: 'уг',\n",
       " 847: 'уд',\n",
       " 848: 'упный',\n",
       " 849: 'уч',\n",
       " 850: 'ученик',\n",
       " 851: 'уще',\n",
       " 852: 'чт',\n",
       " 853: 'ши',\n",
       " 854: 'шина',\n",
       " 855: 'шк',\n",
       " 856: 'шт',\n",
       " 857: 'щег',\n",
       " 858: 'щим',\n",
       " 859: 'щих',\n",
       " 860: 'ые',\n",
       " 861: 'ый',\n",
       " 862: 'эт',\n",
       " 863: 'южн',\n",
       " 864: 'ятельна',\n",
       " 865: 'irl',\n",
       " 866: 'агрессивный',\n",
       " 867: 'азер',\n",
       " 868: 'азкун',\n",
       " 869: 'акт',\n",
       " 870: 'ауешник',\n",
       " 871: 'ауешникнуть',\n",
       " 872: 'баранов',\n",
       " 873: 'бляесть',\n",
       " 874: 'больший',\n",
       " 875: 'бояться',\n",
       " 876: 'братухаборцуха',\n",
       " 877: 'бросать',\n",
       " 878: 'бросить',\n",
       " 879: 'бугуртеть',\n",
       " 880: 'быдло',\n",
       " 881: 'быдлойд',\n",
       " 882: 'быдлойда',\n",
       " 883: 'важно',\n",
       " 884: 'виноватый',\n",
       " 885: 'воистину',\n",
       " 886: 'вокруг',\n",
       " 887: 'волын',\n",
       " 888: 'воспитывать',\n",
       " 889: 'вскрыться',\n",
       " 890: 'вспомнить',\n",
       " 891: 'выберали',\n",
       " 892: 'выжигаться',\n",
       " 893: 'выжить',\n",
       " 894: 'вырожденческий',\n",
       " 895: 'высасывать',\n",
       " 896: 'говно',\n",
       " 897: 'говномидас',\n",
       " 898: 'гопник',\n",
       " 899: 'гопот',\n",
       " 900: 'гора',\n",
       " 901: 'группа',\n",
       " 902: 'давать',\n",
       " 903: 'даг',\n",
       " 904: 'даги',\n",
       " 905: 'дербент',\n",
       " 906: 'деревня',\n",
       " 907: 'дикарямиа',\n",
       " 908: 'доходяга',\n",
       " 909: 'дырка',\n",
       " 910: 'ебал',\n",
       " 911: 'ебали',\n",
       " 912: 'жирика',\n",
       " 913: 'залить',\n",
       " 914: 'замечать',\n",
       " 915: 'заставить',\n",
       " 916: 'затронуть',\n",
       " 917: 'захватить',\n",
       " 918: 'защищать',\n",
       " 919: 'зуб',\n",
       " 920: 'избивать',\n",
       " 921: 'измениться',\n",
       " 922: 'история',\n",
       " 923: 'итог',\n",
       " 924: 'кавказский',\n",
       " 925: 'класс',\n",
       " 926: 'кодер',\n",
       " 927: 'колено',\n",
       " 928: 'колокольня',\n",
       " 929: 'конечный',\n",
       " 930: 'кочевник',\n",
       " 931: 'кошмарил',\n",
       " 932: 'кошмаритя',\n",
       " 933: 'кулак',\n",
       " 934: 'кущёвский',\n",
       " 935: 'лицо',\n",
       " 936: 'лично',\n",
       " 937: 'локальный',\n",
       " 938: 'лоля',\n",
       " 939: 'любить',\n",
       " 940: 'масса',\n",
       " 941: 'митинг',\n",
       " 942: 'мозг',\n",
       " 943: 'морозиться',\n",
       " 944: 'мочить',\n",
       " 945: 'набитый',\n",
       " 946: 'нагиб',\n",
       " 947: 'наебал',\n",
       " 948: 'нападать',\n",
       " 949: 'напористый',\n",
       " 950: 'народпидор',\n",
       " 951: 'настолько',\n",
       " 952: 'нациковы',\n",
       " 953: 'незнание',\n",
       " 954: 'нихуй',\n",
       " 955: 'нормальный',\n",
       " 956: 'обоссать',\n",
       " 957: 'образ',\n",
       " 958: 'обыкновенный',\n",
       " 959: 'обычный',\n",
       " 960: 'ожидать',\n",
       " 961: 'оккупация',\n",
       " 962: 'округа',\n",
       " 963: 'омежный',\n",
       " 964: 'онли',\n",
       " 965: 'оно',\n",
       " 966: 'опасность',\n",
       " 967: 'осман',\n",
       " 968: 'особенно',\n",
       " 969: 'отвественный',\n",
       " 970: 'очередной',\n",
       " 971: 'ошибка',\n",
       " 972: 'палец',\n",
       " 973: 'пара',\n",
       " 974: 'перс',\n",
       " 975: 'пидорашка',\n",
       " 976: 'план',\n",
       " 977: 'плоховато',\n",
       " 978: 'поделить',\n",
       " 979: 'посадить',\n",
       " 980: 'поставить',\n",
       " 981: 'постоянно',\n",
       " 982: 'построить',\n",
       " 983: 'похожий',\n",
       " 984: 'почитай',\n",
       " 985: 'поёбка',\n",
       " 986: 'превышение',\n",
       " 987: 'предел',\n",
       " 988: 'представлять',\n",
       " 989: 'приезжать',\n",
       " 990: 'признать',\n",
       " 991: 'прийти',\n",
       " 992: 'принцип',\n",
       " 993: 'причина',\n",
       " 994: 'проигрывать',\n",
       " 995: 'прочее',\n",
       " 996: 'прочий',\n",
       " 997: 'прошлый',\n",
       " 998: 'разобрать',\n",
       " 999: 'рашер',\n",
       " ...}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1), (1, 1), (2, 1)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_dictionary.doc2bow(df.iloc[0,0], allow_update=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.comment\n",
    "y = df.toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Формирую из списков слов строки\n",
    "X = X.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'единый диспетчерская служба везде'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([ \n",
    "                     ('doc_tfidf', TfidfVectorizer(stop_words=stopword_ru, max_features= 1000)), \n",
    "                     ('clf', xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss'))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('doc_tfidf',\n",
       "                 TfidfVectorizer(max_features=1000,\n",
       "                                 stop_words=['и', 'в', 'во', 'не', 'что', 'он',\n",
       "                                             'на', 'я', 'с', 'со', 'как', 'а',\n",
       "                                             'то', 'все', 'она', 'так', 'его',\n",
       "                                             'но', 'да', 'ты', 'к', 'у', 'же',\n",
       "                                             'вы', 'за', 'бы', 'по', 'только',\n",
       "                                             'ее', 'мне', ...])),\n",
       "                ('clf',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, eva...\n",
       "                               gamma=0, gpu_id=-1, importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7149130683368004"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    nontoxic       0.79      0.96      0.86      2906\n",
      "       toxic       0.84      0.47      0.61      1418\n",
      "\n",
      "    accuracy                           0.80      4324\n",
      "   macro avg       0.82      0.71      0.74      4324\n",
      "weighted avg       0.81      0.80      0.78      4324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['nontoxic', 'toxic']\n",
    "print(classification_report(y_test, y_preds, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'clf__n_estimators':[100, 150, 200, 250, 300],\n",
    "        'clf__learning_rate':[0.1, 0.05, 0.01],\n",
    "        'clf__max_depth':[3, 5, 7, 10, 15, 20],\n",
    "        'clf__subsample': [0.5, 0.7, 0.9, 1],\n",
    "        'clf__tree_method': ['gpu_hist']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = GridSearchCV(pipeline,\n",
    "                    param_grid=params,\n",
    "                    cv=10,\n",
    "                    refit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9h 37min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search = grids.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__learning_rate': 0.1,\n",
       " 'clf__max_depth': 5,\n",
       " 'clf__n_estimators': 300,\n",
       " 'clf__subsample': 0.5,\n",
       " 'clf__tree_method': 'gpu_hist'}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7296813794893577"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pipeline = Pipeline([ \n",
    "                     ('doc_tfidf', TfidfVectorizer(stop_words=stopword_ru, max_features= 1000)), \n",
    "                     ('clf', xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss',\n",
    "                                              learning_rate=0.1, max_depth=5, n_estimators=300,\n",
    "                                              subsample=0.5, tree_method='gpu_hist'))\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('doc_tfidf',\n",
       "                 TfidfVectorizer(max_features=1000,\n",
       "                                 stop_words=['и', 'в', 'во', 'не', 'что', 'он',\n",
       "                                             'на', 'я', 'с', 'со', 'как', 'а',\n",
       "                                             'то', 'все', 'она', 'так', 'его',\n",
       "                                             'но', 'да', 'ты', 'к', 'у', 'же',\n",
       "                                             'вы', 'за', 'бы', 'по', 'только',\n",
       "                                             'ее', 'мне', ...])),\n",
       "                ('clf',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, eva...\n",
       "                               gamma=0, gpu_id=0, importance_type='gain',\n",
       "                               interaction_constraints='', learning_rate=0.1,\n",
       "                               max_delta_step=0, max_depth=5,\n",
       "                               min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=300,\n",
       "                               n_jobs=12, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=0.5, tree_method='gpu_hist',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "score = cross_validate(final_pipeline, X, y, scoring=['roc_auc', 'f1_weighted'], n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([18.23399901, 18.50601912, 18.65699816, 17.89799738, 18.74299836]),\n",
       " 'score_time': array([0.14499879, 0.12697744, 0.14399934, 0.11699915, 0.15299892]),\n",
       " 'test_roc_auc': array([0.69878773, 0.82613068, 0.80631005, 0.73637538, 0.78289831]),\n",
       " 'test_f1_weighted': array([0.70198968, 0.75751229, 0.72411972, 0.6374402 , 0.70847016])}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7701004330279135"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score['test_roc_auc'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7059064095978913"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score['test_f1_weighted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
